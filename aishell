#!/bin/bash
# aishell - AI Shell Container Launcher
# Launches an ephemeral container with project mounted at host path

set -e

VERSION="0.1.0"
BASE_IMAGE_NAME="aishell:base"
VERBOSE=false

# --- Image Tag Computation ---
# Compute image tag based on version specifications
# Returns versioned tag (e.g., aishell:claude-2.0.22) or base tag
compute_image_tag() {
    local suffix=""

    # Build suffix from versions
    if [[ -n "$CLAUDE_VERSION" ]]; then
        suffix="${suffix:+$suffix-}claude-$CLAUDE_VERSION"
    fi
    if [[ -n "$OPENCODE_VERSION" ]]; then
        suffix="${suffix:+$suffix-}opencode-$OPENCODE_VERSION"
    fi

    # Return tagged name or base
    if [[ -n "$suffix" ]]; then
        echo "aishell:$suffix"
    else
        echo "$BASE_IMAGE_NAME"
    fi
}
WITH_CLAUDE=false
WITH_OPENCODE=false
CLAUDE_VERSION=""
OPENCODE_VERSION=""
HARNESS_CMD=""
HARNESS_ARGS=()
FORCE_REBUILD=false
BUILD_ARGS=()
IMAGE_TO_RUN=""

# --- Color Support ---
supports_color() {
    [[ ! -t 1 ]] && return 1
    [[ -n "$NO_COLOR" ]] && return 1
    [[ -n "$FORCE_COLOR" ]] && return 0
    local colors
    colors=$(tput colors 2>/dev/null) || return 1
    [[ "$colors" -ge 8 ]]
}

if supports_color; then
    RED='\033[0;31m'
    YELLOW='\033[0;33m'
    NC='\033[0m'
else
    RED=''
    YELLOW=''
    NC=''
fi

# --- Output Functions ---
error() {
    echo -e "${RED}Error:${NC} $1" >&2
    exit 1
}

warn() {
    echo -e "${YELLOW}Warning:${NC} $1" >&2
}

verbose() {
    [[ "$VERBOSE" == true ]] && echo "$1" >&2 || true
}

# --- Spinner for Long Operations ---
spinner_pid=""

start_spinner() {
    local msg="$1"
    local spin='|/-\'
    local i=0

    # Only show spinner if stderr is a TTY
    [[ ! -t 2 ]] && return

    while true; do
        printf "\r%s %c " "$msg" "${spin:i++%${#spin}:1}" >&2
        sleep 0.1
    done &
    spinner_pid=$!
}

stop_spinner() {
    if [[ -n "$spinner_pid" ]]; then
        kill "$spinner_pid" 2>/dev/null
        spinner_pid=""
        printf "\r\033[K" >&2  # Clear line only if spinner was active
    fi
}

trap 'stop_spinner' EXIT

# --- Embedded Build Files (Heredocs) ---
# These functions write the embedded Dockerfile, entrypoint.sh, and bashrc.aishell
# to a target directory. Used when building the base image.

write_dockerfile() {
    local target_dir="$1"
    cat > "${target_dir}/Dockerfile" << 'DOCKERFILE_EOF'
# Aishell Base Image
# Debian-based container with dynamic user creation, gosu for user switching,
# and basic development tools for agentic AI harnesses.

# Stage 1: Node.js source (for multi-stage copy)
FROM node:24-bookworm-slim AS node-source

# Stage 2: Main image
FROM debian:bookworm-slim

# Build arguments for optional harness installation
ARG WITH_CLAUDE=false
ARG WITH_OPENCODE=false
ARG CLAUDE_VERSION=""
ARG OPENCODE_VERSION=""

# Build arguments for developer tools
ARG BABASHKA_VERSION=1.12.214

# Avoid prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive

# Install required packages in single layer
RUN apt-get update && apt-get install -y --no-install-recommends \
    bash \
    ca-certificates \
    curl \
    git \
    jq \
    less \
    ripgrep \
    sudo \
    vim \
    && rm -rf /var/lib/apt/lists/*

# Install Node.js via multi-stage copy from official image
COPY --from=node-source /usr/local/bin/node /usr/local/bin/node
COPY --from=node-source /usr/local/lib/node_modules /usr/local/lib/node_modules
RUN ln -s /usr/local/lib/node_modules/npm/bin/npm-cli.js /usr/local/bin/npm \
    && ln -s /usr/local/lib/node_modules/npm/bin/npx-cli.js /usr/local/bin/npx \
    && node --version \
    && npm --version

# Install Babashka (static binary for container compatibility)
RUN set -eux; \
    curl -fsSL "https://github.com/babashka/babashka/releases/download/v${BABASHKA_VERSION}/babashka-${BABASHKA_VERSION}-linux-amd64-static.tar.gz" \
    | tar -xz -C /usr/local/bin bb; \
    chmod +x /usr/local/bin/bb; \
    bb --version

# Install gosu 1.19 for proper user switching
# Source: https://github.com/tianon/gosu
RUN set -eux; \
    dpkgArch="$(dpkg --print-architecture)"; \
    curl -fsSL "https://github.com/tianon/gosu/releases/download/1.19/gosu-${dpkgArch}" -o /usr/local/bin/gosu; \
    chmod +x /usr/local/bin/gosu; \
    gosu --version; \
    gosu nobody true

# Install Claude Code if requested (npm global)
# npm global installs to /usr/local/bin/claude which matches doctor's expectations
RUN if [ "$WITH_CLAUDE" = "true" ]; then \
        if [ -n "$CLAUDE_VERSION" ]; then \
            npm install -g @anthropic-ai/claude-code@"$CLAUDE_VERSION"; \
        else \
            npm install -g @anthropic-ai/claude-code; \
        fi \
    fi

# Install OpenCode if requested (native binary)
# Installs to /root/.opencode/bin/opencode, copy to /usr/local/bin for PATH
# Copy instead of symlink because /root/ is not accessible after privilege drop
# Version syntax: VERSION=<version> env var (no v prefix, e.g., 1.1.25)
RUN if [ "$WITH_OPENCODE" = "true" ]; then \
        if [ -n "$OPENCODE_VERSION" ]; then \
            VERSION="$OPENCODE_VERSION" curl -fsSL https://opencode.ai/install | bash; \
        else \
            curl -fsSL https://opencode.ai/install | bash; \
        fi && \
        cp /root/.opencode/bin/opencode /usr/local/bin/opencode && \
        chmod +x /usr/local/bin/opencode; \
    fi

# Copy entrypoint script
COPY entrypoint.sh /usr/local/bin/entrypoint.sh
RUN chmod +x /usr/local/bin/entrypoint.sh

# Copy custom bashrc
COPY bashrc.aishell /etc/bash.aishell

ENTRYPOINT ["/usr/local/bin/entrypoint.sh"]
CMD ["/bin/bash"]
DOCKERFILE_EOF
}

write_entrypoint() {
    local target_dir="$1"
    cat > "${target_dir}/entrypoint.sh" << 'ENTRYPOINT_EOF'
#!/bin/bash
# entrypoint.sh - Dynamic user creation with gosu
# Creates a user at container startup that matches the host user's UID/GID

set -e

# Read UID/GID/HOME from environment variables
USER_ID=${LOCAL_UID:-1000}
GROUP_ID=${LOCAL_GID:-1000}
USER_HOME=${LOCAL_HOME:-/home/developer}
USERNAME=developer

# Create group if GID doesn't exist
if ! getent group "$GROUP_ID" > /dev/null 2>&1; then
    groupadd -g "$GROUP_ID" "$USERNAME" 2>/dev/null || true
fi

# Create user if UID doesn't exist
# Use -d to set home directory to match host path (for config mounts)
if ! getent passwd "$USER_ID" > /dev/null 2>&1; then
    useradd --shell /bin/bash \
        -u "$USER_ID" \
        -g "$GROUP_ID" \
        -d "$USER_HOME" \
        -o \
        -c "Container User" \
        -m "$USERNAME" 2>/dev/null || true
fi

# Get the username for this UID (might be different if user already existed)
ACTUAL_USER=$(getent passwd "$USER_ID" | cut -d: -f1)
# Use LOCAL_HOME if provided, otherwise fall back to passwd entry
export HOME=${LOCAL_HOME:-$(getent passwd "$USER_ID" | cut -d: -f6)}

# Ensure home directory exists with correct ownership
mkdir -p "$HOME"
chown "$USER_ID:$GROUP_ID" "$HOME"

# Create XDG standard directories (apps expect these to be writable)
mkdir -p "$HOME/.local/state" "$HOME/.local/share" "$HOME/.local/bin"
chown -R "$USER_ID:$GROUP_ID" "$HOME/.local"

# Configure git safe.directory to trust the mounted project path (GIT-02)
# PWD is set by docker run -w flag
# Must run after home directory exists (git config --global needs $HOME/.gitconfig writable)
# Must run before exec gosu (runs as root, can write to the gitconfig that will be owned by user)
if [ -n "$PWD" ]; then
    git config --global --add safe.directory "$PWD"
fi

# Setup passwordless sudo for the user
echo "$ACTUAL_USER ALL=(ALL) NOPASSWD:ALL" > /etc/sudoers.d/developer
chmod 0440 /etc/sudoers.d/developer

# Source custom bashrc if starting bash
if [ "$1" = "/bin/bash" ] || [ "$1" = "bash" ]; then
    # Only add source line if not already present
    if ! grep -q "source /etc/bash.aishell" "$HOME/.bashrc" 2>/dev/null; then
        echo "source /etc/bash.aishell" >> "$HOME/.bashrc"
    fi
fi

# Add harness bin directories to PATH if they exist
[[ -d /usr/local/bin ]] && export PATH="/usr/local/bin:$PATH"

# Execute pre-start command if specified (PRE-01, PRE-02, PRE-03)
if [[ -n "${PRE_START:-}" ]]; then
    # Run in background, redirect all output to log file
    # Using sh -c ensures proper argument handling for complex commands
    sh -c "$PRE_START" > /tmp/pre-start.log 2>&1 &
fi

# Execute command as the user via gosu
exec gosu "$USER_ID:$GROUP_ID" "$@"
ENTRYPOINT_EOF
    chmod +x "${target_dir}/entrypoint.sh"
}

write_bashrc() {
    local target_dir="$1"
    cat > "${target_dir}/bashrc.aishell" << 'BASHRC_EOF'
# /etc/bash.aishell - Custom shell configuration for aishell containers

# UTF-8 locale for Unicode character support (statusline, symbols)
# C.UTF-8 is available by default in Debian without installing locales package
export LANG=C.UTF-8
export LC_ALL=C.UTF-8

# Limit directory depth in prompt (shows .../parent/current instead of full path)
export PROMPT_DIRTRIM=2

# Custom prompt: [aishell] ~/project $
# Cyan [aishell] prefix, then working directory, then $
export PS1='\[\033[0;36m\][aishell]\[\033[0m\] \w \$ '

# Useful aliases
alias ll='ls -la'
alias la='ls -A'

# Ensure colors in common commands
alias ls='ls --color=auto'
alias grep='grep --color=auto'

# Set editor
export EDITOR=vim
export VISUAL=vim

# History settings
export HISTSIZE=10000
export HISTFILESIZE=20000
export HISTCONTROL=ignoreboth:erasedups
BASHRC_EOF
}

# --- State Management ---
# Get unique hash for project path (for state file naming)
get_project_hash() {
    local project_dir="$1"
    local canonical_path

    # Resolve to canonical path (handles symlinks, .., etc)
    canonical_path=$(realpath "$project_dir" 2>/dev/null) || canonical_path="$project_dir"

    # Hash and truncate to 12 chars (matches existing pattern for extended images)
    echo -n "$canonical_path" | sha256sum | cut -c1-12
}

# Create and return state directory path
setup_state_dir() {
    local state_base="${XDG_STATE_HOME:-$HOME/.local/state}"
    local state_dir="$state_base/aishell/builds"

    mkdir -p "$state_dir"
    echo "$state_dir"
}

# Get state file path for a project
get_state_file() {
    local project_dir="$1"
    local state_dir hash

    state_dir=$(setup_state_dir)
    hash=$(get_project_hash "$project_dir")

    echo "$state_dir/$hash.state"
}

# Atomically write build state to file
write_state_file() {
    local state_file="$1"
    local project_path="$2"
    local with_claude="$3"
    local with_opencode="$4"
    local claude_version="$5"
    local opencode_version="$6"
    local image_tag="$7"

    local tmp_file
    tmp_file=$(mktemp)

    cat > "$tmp_file" << EOF
# aishell build state - DO NOT EDIT MANUALLY
# Project: $project_path
# Built: $(date -Iseconds)
BUILD_WITH_CLAUDE=$with_claude
BUILD_WITH_OPENCODE=$with_opencode
BUILD_CLAUDE_VERSION="$claude_version"
BUILD_OPENCODE_VERSION="$opencode_version"
BUILD_IMAGE_TAG="$image_tag"
BUILD_TIMESTAMP="$(date -Iseconds)"
EOF

    # Atomic move
    mv "$tmp_file" "$state_file"
}

# Safely read and validate state file
read_state_file() {
    local state_file="$1"

    # Initialize defaults
    BUILD_WITH_CLAUDE=false
    BUILD_WITH_OPENCODE=false
    BUILD_CLAUDE_VERSION=""
    BUILD_OPENCODE_VERSION=""
    BUILD_IMAGE_TAG=""
    BUILD_TIMESTAMP=""

    [[ ! -f "$state_file" ]] && return 1

    # Validate: only comments, empty lines, and BUILD_VAR=value allowed
    # Security: prevents code injection via malicious state files
    if grep -qvE '^(#.*|BUILD_[A-Z_]+="?[^"]*"?|[[:space:]]*)$' "$state_file"; then
        warn "State file appears corrupted: $state_file"
        return 1
    fi

    # Safe to source
    # shellcheck source=/dev/null
    source "$state_file"
    return 0
}

# --- Runtime Config Parsing ---
# Allowed variable names for run.conf (whitelist)
readonly RUNCONF_ALLOWED_VARS="MOUNTS|ENV|PORTS|DOCKER_ARGS|PRE_START"

# Parse .aishell/run.conf safely
# Sets CONF_* variables for each allowed config option
# Returns 0 on success, exits 1 on syntax error
parse_run_conf() {
    local config_file="$1"
    local line_num=0

    # Initialize config variables
    declare -g CONF_MOUNTS=""
    declare -g CONF_ENV=""
    declare -g CONF_PORTS=""
    declare -g CONF_DOCKER_ARGS=""
    declare -g CONF_PRE_START=""

    # No config file is valid (use defaults)
    [[ ! -f "$config_file" ]] && return 0

    while IFS= read -r line || [[ -n "$line" ]]; do
        ((line_num++))

        # Skip empty lines (including whitespace-only)
        [[ -z "${line// /}" ]] && continue

        # Skip comments
        [[ "$line" =~ ^[[:space:]]*# ]] && continue

        # Trim leading whitespace
        line="${line#"${line%%[![:space:]]*}"}"
        # Trim trailing whitespace
        line="${line%"${line##*[![:space:]]}"}"

        # Validate: ALLOWED_VAR=value or ALLOWED_VAR="value"
        if [[ "$line" =~ ^($RUNCONF_ALLOWED_VARS)=(.*)$ ]]; then
            local var_name="${BASH_REMATCH[1]}"
            local var_value="${BASH_REMATCH[2]}"

            # Remove surrounding quotes (double or single)
            if [[ "$var_value" =~ ^\"(.*)\"$ ]]; then
                var_value="${BASH_REMATCH[1]}"
            elif [[ "$var_value" =~ ^\'(.*)\'$ ]]; then
                var_value="${BASH_REMATCH[1]}"
            fi

            # Set CONF_ prefixed variable
            declare -g "CONF_${var_name}=$var_value"
        else
            # Provide helpful error with line number and context
            # Build multiline message for error() function
            local err_msg="Config error in $config_file line $line_num:
  $line

Expected format: VARIABLE=value or VARIABLE=\"value with spaces\"
Allowed variables: MOUNTS, ENV, PORTS, DOCKER_ARGS, PRE_START"
            error "$err_msg"
        fi
    done < "$config_file"

    return 0
}

# Build mount arguments from MOUNTS config
# Expands $HOME, ${HOME}, ~ and outputs -v flags
build_mount_args() {
    local mounts_str="$1"

    [[ -z "$mounts_str" ]] && return 0

    # Split on whitespace
    for mount_path in $mounts_str; do
        local expanded="$mount_path"

        # Expand $HOME
        expanded="${expanded//\$HOME/$HOME}"

        # Expand ${HOME}
        expanded="${expanded//\$\{HOME\}/$HOME}"

        # Handle ~ at start
        if [[ "$expanded" == "~"* ]]; then
            expanded="$HOME${expanded:1}"
        fi

        # Resolve to absolute path if exists
        if [[ -e "$expanded" ]]; then
            expanded=$(realpath "$expanded")
        else
            warn "Mount source does not exist: $expanded"
        fi

        # Output mount flags (same path in container)
        printf '%s\n' "-v"
        printf '%s\n' "$expanded:$expanded"
    done
}

# Build environment arguments from ENV config
# Handles VAR (passthrough) and VAR=value (literal) syntax
build_env_args() {
    local env_str="$1"

    [[ -z "$env_str" ]] && return 0

    for env_entry in $env_str; do
        if [[ "$env_entry" == *"="* ]]; then
            # Literal value: VAR=value
            printf '%s\n' "-e"
            printf '%s\n' "$env_entry"
        else
            # Passthrough: VAR (inherit from host)
            if [[ -v "$env_entry" ]]; then
                printf '%s\n' "-e"
                printf '%s\n' "$env_entry"
            else
                warn "Skipping unset host variable: $env_entry"
            fi
        fi
    done
}

# Build port arguments from PORTS config
# Validates format and outputs -p flags
build_port_args() {
    local ports_str="$1"

    [[ -z "$ports_str" ]] && return 0

    for port_spec in $ports_str; do
        # Validate format: host:container or host:container/protocol
        if [[ "$port_spec" =~ ^[0-9]+:[0-9]+(/[a-z]+)?$ ]]; then
            printf '%s\n' "-p"
            printf '%s\n' "$port_spec"
        else
            error "Invalid port mapping: $port_spec
Expected format: HOST_PORT:CONTAINER_PORT (e.g., 8080:80)
Optional protocol: 8080:80/udp"
        fi
    done
}

# Apply runtime configuration to docker_args array
# Reads run.conf and appends appropriate flags
apply_runtime_config() {
    local project_dir="$1"
    local -n docker_args_ref="$2"

    local config_file="$project_dir/.aishell/run.conf"

    # Parse config (sets CONF_* variables)
    parse_run_conf "$config_file"

    # Add mounts
    if [[ -n "$CONF_MOUNTS" ]]; then
        while IFS= read -r arg; do
            [[ -n "$arg" ]] && docker_args_ref+=("$arg")
        done < <(build_mount_args "$CONF_MOUNTS")
    fi

    # Add environment variables
    if [[ -n "$CONF_ENV" ]]; then
        while IFS= read -r arg; do
            [[ -n "$arg" ]] && docker_args_ref+=("$arg")
        done < <(build_env_args "$CONF_ENV")
    fi

    # Add port mappings
    if [[ -n "$CONF_PORTS" ]]; then
        while IFS= read -r arg; do
            [[ -n "$arg" ]] && docker_args_ref+=("$arg")
        done < <(build_port_args "$CONF_PORTS")
    fi

    # Add extra docker arguments (word splitting intentional)
    if [[ -n "$CONF_DOCKER_ARGS" ]]; then
        # shellcheck disable=SC2206
        docker_args_ref+=($CONF_DOCKER_ARGS)
    fi
}

# Display what will be built (user feedback before long-running build)
show_build_preview() {
    local with_claude="$1"
    local with_opencode="$2"
    local claude_version="$3"
    local opencode_version="$4"
    local is_update="$5"

    local action="Building"
    [[ "$is_update" == true ]] && action="Updating"

    echo "$action image with:"

    if [[ "$with_claude" == true ]]; then
        if [[ -n "$claude_version" ]]; then
            echo "  - Claude Code v$claude_version"
        else
            echo "  - Claude Code (latest)"
        fi
    fi

    if [[ "$with_opencode" == true ]]; then
        if [[ -n "$opencode_version" ]]; then
            echo "  - OpenCode v$opencode_version"
        else
            echo "  - OpenCode (latest)"
        fi
    fi

    if [[ "$with_claude" != true ]] && [[ "$with_opencode" != true ]]; then
        echo "  - Base image only (shell access)"
    fi

    echo ""
}

# --- Build Command ---
# Explicit build subcommand with state persistence
do_build() {
    local args=("$@")
    local with_claude=false
    local with_opencode=false
    local claude_version=""
    local opencode_version=""
    local no_cache=false
    local verbose_build=false

    # Parse build-specific args
    for arg in "${args[@]}"; do
        case "$arg" in
            --with-claude)
                with_claude=true
                ;;
            --with-opencode)
                with_opencode=true
                ;;
            --claude-version=*)
                claude_version="${arg#--claude-version=}"
                ;;
            --opencode-version=*)
                opencode_version="${arg#--opencode-version=}"
                ;;
            --no-cache|--rebuild)
                no_cache=true
                ;;
            -v|--verbose)
                verbose_build=true
                ;;
            -h|--help)
                echo "Usage: aishell build [OPTIONS]"
                echo ""
                echo "Build the container image."
                echo ""
                echo "Options:"
                echo "    --with-claude           Include Claude Code"
                echo "    --with-opencode         Include OpenCode"
                echo "    --claude-version=X.Y.Z  Specific Claude Code version"
                echo "    --opencode-version=X.Y.Z Specific OpenCode version"
                echo "    --no-cache              Force rebuild (ignore Docker cache)"
                echo "    -v, --verbose           Show detailed build output"
                echo "    -h, --help              Show this help"
                exit 0
                ;;
        esac
    done

    check_docker

    local project_dir
    project_dir="$(pwd)"

    # Show build preview
    show_build_preview "$with_claude" "$with_opencode" "$claude_version" "$opencode_version" false

    # Compute target tag
    # Set global version vars for compute_image_tag
    CLAUDE_VERSION="$claude_version"
    OPENCODE_VERSION="$opencode_version"
    local target_tag
    target_tag=$(compute_image_tag)

    # Create temp directory for build files
    local build_dir
    build_dir=$(mktemp -d)
    # shellcheck disable=SC2064
    trap "rm -rf '$build_dir'" RETURN

    # Write embedded build files to temp directory
    write_dockerfile "$build_dir"
    write_entrypoint "$build_dir"
    write_bashrc "$build_dir"

    # Build docker args
    local -a build_args=()
    [[ "$no_cache" == true ]] && build_args+=(--no-cache)
    [[ "$with_claude" == true ]] && build_args+=(--build-arg WITH_CLAUDE=true)
    [[ "$with_opencode" == true ]] && build_args+=(--build-arg WITH_OPENCODE=true)
    [[ -n "$claude_version" ]] && build_args+=(--build-arg "CLAUDE_VERSION=$claude_version")
    [[ -n "$opencode_version" ]] && build_args+=(--build-arg "OPENCODE_VERSION=$opencode_version")

    # Build the image
    if [[ "$verbose_build" == true ]]; then
        if ! docker build "${build_args[@]}" -t "$target_tag" --progress=plain "$build_dir"; then
            error "Build failed"
        fi
    else
        local build_log
        build_log=$(mktemp)
        # shellcheck disable=SC2064
        trap "rm -rf '$build_dir' '$build_log'" RETURN

        start_spinner "Building image"
        if docker build "${build_args[@]}" -t "$target_tag" "$build_dir" > "$build_log" 2>&1; then
            stop_spinner
        else
            stop_spinner
            error "Build failed:
$(cat "$build_log")"
        fi
    fi

    # Write state file after successful build
    local state_file
    state_file=$(get_state_file "$project_dir")
    write_state_file "$state_file" "$project_dir" "$with_claude" "$with_opencode" "$claude_version" "$opencode_version" "$target_tag"

    echo "Build complete. Image: $target_tag"
}

# --- Git Identity ---
read_git_identity() {
    local project_dir="$1"

    # Check if git is installed on host
    if ! command -v git &> /dev/null; then
        echo ""
        echo ""
        return 0
    fi

    # Read effective config (local overrides global)
    # git -C runs command as if started in <path>
    local name email
    name=$(git -C "$project_dir" config user.name 2>/dev/null) || name=""
    email=$(git -C "$project_dir" config user.email 2>/dev/null) || email=""

    echo "$name"
    echo "$email"
}

# --- Harness Config Mounts ---
build_config_mounts() {
    # Output mount flags, one per line as "-v src:dst"
    # Claude Code configs
    [[ -d "$HOME/.claude" ]] && echo "-v $HOME/.claude:$HOME/.claude"
    [[ -f "$HOME/.claude.json" ]] && echo "-v $HOME/.claude.json:$HOME/.claude.json"

    # OpenCode configs
    [[ -d "$HOME/.config/opencode" ]] && echo "-v $HOME/.config/opencode:$HOME/.config/opencode"

    # OpenCode credentials (auth.json from /connect)
    [[ -d "$HOME/.local/share/opencode" ]] && echo "-v $HOME/.local/share/opencode:$HOME/.local/share/opencode"
}

# --- API Key Environment Variables ---
build_api_env() {
    # Output env flags, one per line as "-e VAR=value"
    # API keys for various providers (only pass if set, avoid empty override)
    local api_vars=(
        ANTHROPIC_API_KEY
        OPENAI_API_KEY
        GEMINI_API_KEY
        GROQ_API_KEY
        GITHUB_TOKEN
        AWS_ACCESS_KEY_ID
        AWS_SECRET_ACCESS_KEY
        AWS_REGION
        AWS_PROFILE
        AZURE_OPENAI_API_KEY
        AZURE_OPENAI_ENDPOINT
        GOOGLE_CLOUD_PROJECT
        GOOGLE_APPLICATION_CREDENTIALS
    )

    for var in "${api_vars[@]}"; do
        [[ -n "${!var:-}" ]] && echo "-e $var=${!var}"
    done

    # Recommended container settings for Claude Code
    echo "-e DISABLE_AUTOUPDATER=1"
}

# --- Docker Checks ---
check_docker() {
    if ! command -v docker &> /dev/null; then
        error "Docker is not installed. Please install Docker and try again."
    fi

    if ! docker info >/dev/null 2>&1; then
        error "Docker is not running. Please start Docker and try again."
    fi
}

# --- Argument Parsing ---
usage() {
    cat << EOF
Usage: aishell [OPTIONS] COMMAND [ARGS...]

Build and run ephemeral containers for AI harnesses.

Commands:
    build       Build the container image
    update      Rebuild with latest versions (uses saved configuration)
    claude      Run Claude Code (requires: aishell build --with-claude)
    opencode    Run OpenCode (requires: aishell build --with-opencode)
    (none)      Enter interactive shell (requires: aishell build)

Build Options:
    --with-claude           Include Claude Code in image
    --with-opencode         Include OpenCode in image
    --claude-version=X.Y.Z  Install specific Claude Code version
    --opencode-version=X.Y.Z Install specific OpenCode version
    --no-cache              Force fresh build (no Docker cache)

Global Options:
    --build-arg KEY=VAL     Pass build argument to Dockerfile
    -v, --verbose           Show detailed output
    -h, --help              Show this help message
    --version               Show version

Project Extensions:
    Place a Dockerfile at .aishell/Dockerfile to extend the base image.

Runtime Configuration:
    Create .aishell/run.conf to configure container runtime:

    MOUNTS="\$HOME/.ssh \$HOME/.config/git"    # Additional volume mounts
    ENV="EDITOR DEBUG_MODE=1"                  # Environment variables
    PORTS="3000:3000 8080:80"                  # Port mappings
    DOCKER_ARGS="--cap-add=SYS_PTRACE"         # Extra docker run args
    PRE_START="redis-server --daemonize yes"   # Background command before shell

    See: https://github.com/user/aishell#runtime-configuration

Examples:
    aishell build --with-claude     # Build with Claude Code
    aishell build                   # Build base image only
    aishell claude                  # Run Claude Code
    aishell                         # Enter shell
    aishell update                  # Rebuild with latest versions
    aishell update --with-opencode  # Add OpenCode to existing build

Environment Variables:
    AISHELL_SKIP_PERMISSIONS   Set to 'false' for permission prompts in Claude

EOF
}

parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --with-claude)
                WITH_CLAUDE=true
                shift
                ;;
            --with-opencode)
                WITH_OPENCODE=true
                shift
                ;;
            --claude-version=*)
                CLAUDE_VERSION="${1#--claude-version=}"
                shift
                ;;
            --opencode-version=*)
                OPENCODE_VERSION="${1#--opencode-version=}"
                shift
                ;;
            --rebuild)
                FORCE_REBUILD=true
                shift
                ;;
            --build-arg)
                if [[ -z "${2:-}" ]] || [[ "$2" == -* ]]; then
                    error "--build-arg requires a KEY=VALUE argument"
                fi
                BUILD_ARGS+=("$2")
                shift 2
                ;;
            --build-arg=*)
                BUILD_ARGS+=("${1#--build-arg=}")
                shift
                ;;
            -v|--verbose)
                VERBOSE=true
                shift
                ;;
            -h|--help)
                usage
                exit 0
                ;;
            --version)
                echo "aishell $VERSION"
                exit 0
                ;;
            claude|opencode)
                HARNESS_CMD="$1"
                shift
                HARNESS_ARGS=("$@")
                break
                ;;
            build)
                HARNESS_CMD="build"
                shift
                HARNESS_ARGS=("$@")
                break
                ;;
            update)
                HARNESS_CMD="update"
                shift
                HARNESS_ARGS=("$@")
                break
                ;;
            -*)
                error "Unknown option: $1"
                ;;
            *)
                # Unknown positional - treat as command to run in shell
                HARNESS_CMD="exec"
                HARNESS_ARGS=("$1" "${@:2}")
                break
                ;;
        esac
    done
}

# --- Project Extension Functions ---
extension_dockerfile() {
    local project_dir="$1"
    local dockerfile="$project_dir/.aishell/Dockerfile"

    if [[ -f "$dockerfile" ]]; then
        echo "$dockerfile"
        return 0
    fi

    return 1
}

get_base_image_id() {
    docker inspect --format='{{.Id}}' "$BASE_IMAGE_NAME" 2>/dev/null
}

needs_extended_rebuild() {
    local extended_tag="$1"
    local current_base_id="$2"

    # Extended image doesn't exist
    if ! docker image inspect "$extended_tag" >/dev/null 2>&1; then
        return 0
    fi

    # Check stored base ID against current
    local stored_base_id
    stored_base_id=$(docker inspect --format='{{index .Config.Labels "aishell.base.id"}}' "$extended_tag" 2>/dev/null)

    if [[ "$stored_base_id" != "$current_base_id" ]]; then
        return 0  # Base changed, need rebuild
    fi

    return 1  # Use cache
}

build_extended_image() {
    local dockerfile="$1"
    local project_dir="$2"
    local image_tag="$3"
    local base_id="$4"
    local force_rebuild="$5"

    local -a build_args=(
        -f "$dockerfile"
        -t "$image_tag"
        --label "aishell.base.id=$base_id"
    )

    # Add --no-cache if force rebuild
    [[ "$force_rebuild" == true ]] && build_args+=(--no-cache)

    # Pass through BUILD_ARGS array
    for arg in "${BUILD_ARGS[@]}"; do
        build_args+=(--build-arg "$arg")
    done

    if [[ "$VERBOSE" == true ]]; then
        if ! docker build "${build_args[@]}" --progress=plain "$project_dir"; then
            error "Build failed"
        fi
    else
        local build_log
        build_log=$(mktemp)
        # shellcheck disable=SC2064
        trap "rm -f '$build_log'" RETURN

        start_spinner "Building project image"
        if docker build "${build_args[@]}" "$project_dir" > "$build_log" 2>&1; then
            stop_spinner
        else
            stop_spinner
            error "Build failed:
$(cat "$build_log")"
        fi
    fi
}

# --- Build Verification ---
# Verify that a build exists for the current project
verify_build_exists() {
    local project_dir="$1"
    local state_file

    state_file=$(get_state_file "$project_dir")

    # Check if state file exists
    if [[ ! -f "$state_file" ]]; then
        return 1
    fi

    # Load state file
    if ! read_state_file "$state_file"; then
        return 1
    fi

    # Check if the built image still exists
    if [[ -n "$BUILD_IMAGE_TAG" ]] && ! docker image inspect "$BUILD_IMAGE_TAG" >/dev/null 2>&1; then
        return 2  # State exists but image is missing
    fi

    # Set IMAGE_TO_RUN from state
    IMAGE_TO_RUN="$BUILD_IMAGE_TAG"
    return 0
}

# Handle extension Dockerfile on top of base image from state
handle_extension() {
    local project_dir="$1"
    local dockerfile

    # Check for extension
    if ! dockerfile=$(extension_dockerfile "$project_dir"); then
        # No extension, use image from state
        return 0
    fi

    # Calculate extended tag (hash of project path for isolation)
    local hash
    hash=$(echo -n "$project_dir" | sha256sum | cut -c1-12)
    local extended_tag="aishell:ext-$hash"

    # Get base image ID (from the image stored in state)
    local base_id
    base_id=$(docker inspect --format='{{.Id}}' "$IMAGE_TO_RUN" 2>/dev/null)

    # Determine if rebuild needed
    local force_rebuild=false
    if needs_extended_rebuild "$extended_tag" "$base_id"; then
        force_rebuild=true
    fi

    # User requested --rebuild
    [[ "$FORCE_REBUILD" == true ]] && force_rebuild=true

    # Build extension (Docker cache handles efficiency if force_rebuild=false)
    build_extended_image "$dockerfile" "$project_dir" "$extended_tag" "$base_id" "$force_rebuild"

    IMAGE_TO_RUN="$extended_tag"
}

# --- Error Helpers ---
# Error shown when no prior build exists
error_no_build() {
    echo -e "${RED}Error:${NC} No previous build found for this project." >&2
    echo "" >&2
    echo "To build with Claude Code:  aishell build --with-claude" >&2
    echo "To build with OpenCode:     aishell build --with-opencode" >&2
    echo "To build base image:        aishell build" >&2
    exit 1
}

# Error shown when harness was not included in build
error_missing_harness() {
    local harness_name="$1"
    echo -e "${RED}Error:${NC} ${harness_name} was not included in the build." >&2
    echo "" >&2
    echo "Current build does not include ${harness_name}." >&2
    echo "" >&2
    echo "To add ${harness_name} to the build:" >&2
    echo "    aishell update --with-${harness_name}" >&2
    echo "" >&2
    echo "Or rebuild with ${harness_name}:" >&2
    echo "    aishell build --with-${harness_name}" >&2
    exit 1
}

# Verify harness is available in current build
verify_harness_available() {
    local harness_name="$1"
    local required_flag_value="$2"

    if [[ "$required_flag_value" != "true" ]]; then
        error_missing_harness "$harness_name"
    fi
    return 0
}

# Error shown when state exists but image is missing
error_image_missing() {
    echo -e "${RED}Error:${NC} Build state found but image is missing." >&2
    echo "" >&2
    echo "The Docker image may have been removed. Rebuild with:" >&2
    echo "  aishell build --with-claude     # (if Claude Code was in original build)" >&2
    echo "  aishell update                  # (to rebuild with saved configuration)" >&2
    exit 1
}

do_update() {
    local args=("$@")
    local new_with_claude=false
    local new_with_opencode=false
    local new_claude_version=""
    local new_opencode_version=""
    local verbose_build=false

    # Parse update-specific args (new flags to add)
    for arg in "${args[@]}"; do
        case "$arg" in
            --with-claude)
                new_with_claude=true
                ;;
            --with-opencode)
                new_with_opencode=true
                ;;
            --claude-version=*)
                new_claude_version="${arg#--claude-version=}"
                ;;
            --opencode-version=*)
                new_opencode_version="${arg#--opencode-version=}"
                ;;
            -v|--verbose)
                verbose_build=true
                ;;
            -h|--help)
                echo "Usage: aishell update [OPTIONS]"
                echo ""
                echo "Rebuild with latest versions using saved configuration."
                echo ""
                echo "Options:"
                echo "    --with-claude           Add Claude Code to existing build"
                echo "    --with-opencode         Add OpenCode to existing build"
                echo "    --claude-version=X.Y.Z  Update to specific Claude Code version"
                echo "    --opencode-version=X.Y.Z Update to specific OpenCode version"
                echo "    -v, --verbose           Show detailed build output"
                echo "    -h, --help              Show this help"
                echo ""
                echo "Update always uses --no-cache to fetch latest versions."
                exit 0
                ;;
        esac
    done

    check_docker

    local project_dir
    project_dir="$(pwd)"

    # Load existing state
    local state_file
    state_file=$(get_state_file "$project_dir")

    if ! read_state_file "$state_file"; then
        error_no_build
    fi

    # Merge new flags with existing state (new flags ADD to existing)
    local with_claude="$BUILD_WITH_CLAUDE"
    local with_opencode="$BUILD_WITH_OPENCODE"
    local claude_version="$BUILD_CLAUDE_VERSION"
    local opencode_version="$BUILD_OPENCODE_VERSION"

    # New flags add to existing (don't replace)
    [[ "$new_with_claude" == true ]] && with_claude=true
    [[ "$new_with_opencode" == true ]] && with_opencode=true

    # Version flags override existing for that harness
    [[ -n "$new_claude_version" ]] && claude_version="$new_claude_version"
    [[ -n "$new_opencode_version" ]] && opencode_version="$new_opencode_version"

    # Show update preview with merged state
    show_build_preview "$with_claude" "$with_opencode" "$claude_version" "$opencode_version" true

    # Compute target tag
    CLAUDE_VERSION="$claude_version"
    OPENCODE_VERSION="$opencode_version"
    local target_tag
    target_tag=$(compute_image_tag)

    # Create temp directory for build files
    local build_dir
    build_dir=$(mktemp -d)
    # shellcheck disable=SC2064
    trap "rm -rf '$build_dir'" RETURN

    # Write embedded build files to temp directory
    write_dockerfile "$build_dir"
    write_entrypoint "$build_dir"
    write_bashrc "$build_dir"

    # Build args - always use --no-cache for update (get latest)
    local -a build_args=(--no-cache)
    [[ "$with_claude" == true ]] && build_args+=(--build-arg WITH_CLAUDE=true)
    [[ "$with_opencode" == true ]] && build_args+=(--build-arg WITH_OPENCODE=true)
    [[ -n "$claude_version" ]] && build_args+=(--build-arg "CLAUDE_VERSION=$claude_version")
    [[ -n "$opencode_version" ]] && build_args+=(--build-arg "OPENCODE_VERSION=$opencode_version")

    # Build the image
    if [[ "$verbose_build" == true ]]; then
        if ! docker build "${build_args[@]}" -t "$target_tag" --progress=plain "$build_dir"; then
            error "Update failed"
        fi
    else
        local build_log
        build_log=$(mktemp)
        # shellcheck disable=SC2064
        trap "rm -rf '$build_dir' '$build_log'" RETURN

        start_spinner "Updating image"
        if docker build "${build_args[@]}" -t "$target_tag" "$build_dir" > "$build_log" 2>&1; then
            stop_spinner
        else
            stop_spinner
            error "Update failed:
$(cat "$build_log")"
        fi
    fi

    # Write updated state
    write_state_file "$state_file" "$project_dir" "$with_claude" "$with_opencode" "$claude_version" "$opencode_version" "$target_tag"

    echo "Update complete. Image: $target_tag"
}

# --- Main ---
main() {
    parse_args "$@"

    # Handle build command
    if [[ "$HARNESS_CMD" == "build" ]]; then
        do_build "${HARNESS_ARGS[@]}"
        exit 0
    fi

    # Handle update command
    if [[ "$HARNESS_CMD" == "update" ]]; then
        do_update "${HARNESS_ARGS[@]}"
        exit 0
    fi

    check_docker

    local project_dir
    project_dir="$(pwd)"

    # Verify build exists (no auto-build - user must run aishell build first)
    local verify_result=0
    verify_build_exists "$project_dir" || verify_result=$?

    case "$verify_result" in
        0)
            # Build exists and image found
            ;;
        1)
            # No state file - need to build
            error_no_build
            ;;
        2)
            # State exists but image missing
            error_image_missing
            ;;
    esac

    # Handle extension Dockerfile if present
    handle_extension "$project_dir"

    # Read git identity from host
    local identity git_name git_email
    identity=$(read_git_identity "$project_dir")
    git_name=$(echo "$identity" | head -1)
    git_email=$(echo "$identity" | tail -1)

    if [[ -z "$git_name" ]] || [[ -z "$git_email" ]]; then
        warn "Git identity not found on host"
    fi

    verbose "Launching container..."
    verbose "  Project: $project_dir"
    verbose "  UID/GID: $(id -u):$(id -g)"
    if [[ -n "$git_name" ]] && [[ -n "$git_email" ]]; then
        verbose "  Git identity: $git_name <$git_email>"
    fi
    [[ -n "$HARNESS_CMD" ]] && verbose "  Command: $HARNESS_CMD ${HARNESS_ARGS[*]}"

    # Build docker run arguments
    local -a docker_args=(
        --rm -it
        -v "$project_dir:$project_dir"
        -w "$project_dir"
        -e "LOCAL_UID=$(id -u)"
        -e "LOCAL_GID=$(id -g)"
        -e "LOCAL_HOME=$HOME"
        -e "TERM=${TERM:-xterm-256color}"
        -e "COLORTERM=${COLORTERM:-truecolor}"
    )

    # Add git identity env vars
    if [[ -n "$git_name" ]] && [[ -n "$git_email" ]]; then
        docker_args+=(
            -e "GIT_AUTHOR_NAME=$git_name"
            -e "GIT_AUTHOR_EMAIL=$git_email"
            -e "GIT_COMMITTER_NAME=$git_name"
            -e "GIT_COMMITTER_EMAIL=$git_email"
        )
    fi

    # Add config mounts (using mapfile for robustness)
    local config_mounts
    config_mounts=$(build_config_mounts)
    if [[ -n "$config_mounts" ]]; then
        while IFS= read -r mount; do
            [[ -n "$mount" ]] && docker_args+=($mount)
        done <<< "$config_mounts"
    fi

    # Add API environment variables
    local api_envs
    api_envs=$(build_api_env)
    if [[ -n "$api_envs" ]]; then
        while IFS= read -r env; do
            [[ -n "$env" ]] && docker_args+=($env)
        done <<< "$api_envs"
    fi

    # Apply runtime configuration from .aishell/run.conf
    local config_file="$project_dir/.aishell/run.conf"
    if [[ -f "$config_file" ]]; then
        verbose "Loading runtime config: $config_file"
        parse_run_conf "$config_file"

        # Add configured mounts
        if [[ -n "$CONF_MOUNTS" ]]; then
            verbose "  MOUNTS: $CONF_MOUNTS"
            while IFS= read -r arg; do
                [[ -n "$arg" ]] && docker_args+=("$arg")
            done < <(build_mount_args "$CONF_MOUNTS")
        fi

        # Add configured environment variables
        if [[ -n "$CONF_ENV" ]]; then
            verbose "  ENV: $CONF_ENV"
            while IFS= read -r arg; do
                [[ -n "$arg" ]] && docker_args+=("$arg")
            done < <(build_env_args "$CONF_ENV")
        fi

        # Add configured port mappings
        if [[ -n "$CONF_PORTS" ]]; then
            verbose "  PORTS: $CONF_PORTS"
            while IFS= read -r arg; do
                [[ -n "$arg" ]] && docker_args+=("$arg")
            done < <(build_port_args "$CONF_PORTS")
        fi

        # Add extra docker arguments (word splitting intentional)
        if [[ -n "$CONF_DOCKER_ARGS" ]]; then
            verbose "  DOCKER_ARGS: $CONF_DOCKER_ARGS"
            # shellcheck disable=SC2206
            docker_args+=($CONF_DOCKER_ARGS)
        fi

        # Pass PRE_START command to container if configured
        if [[ -n "${CONF_PRE_START:-}" ]]; then
            verbose "  PRE_START: $CONF_PRE_START"
            docker_args+=(-e "PRE_START=$CONF_PRE_START")
        fi
    fi

    # Dispatch based on command
    case "$HARNESS_CMD" in
        claude)
            # Verify Claude was included in the build
            verify_harness_available "claude" "$BUILD_WITH_CLAUDE"
            local claude_args=()
            # Default: skip permissions (container is the sandbox)
            # Opt-out: AISHELL_SKIP_PERMISSIONS=false
            if [[ "${AISHELL_SKIP_PERMISSIONS:-true}" != "false" ]]; then
                claude_args+=(--dangerously-skip-permissions)
            fi
            exec docker run "${docker_args[@]}" "$IMAGE_TO_RUN" claude "${claude_args[@]}" "${HARNESS_ARGS[@]}"
            ;;
        opencode)
            # Verify OpenCode was included in the build
            verify_harness_available "opencode" "$BUILD_WITH_OPENCODE"
            exec docker run "${docker_args[@]}" "$IMAGE_TO_RUN" opencode "${HARNESS_ARGS[@]}"
            ;;
        exec)
            exec docker run "${docker_args[@]}" "$IMAGE_TO_RUN" "${HARNESS_ARGS[@]}"
            ;;
        *)
            exec docker run "${docker_args[@]}" "$IMAGE_TO_RUN" /bin/bash
            ;;
    esac
}

main "$@"
